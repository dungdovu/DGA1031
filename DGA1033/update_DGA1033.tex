\documentclass{beamer}
\mode<presentation> {

% The Beamer class comes with a number of default slide themes
% which change the colors and layouts of slides. Below this is a list
% of all the themes, uncomment each in turn to see what they look like.
\usepackage{graphicx}
\usepackage{svg}

\usepackage{graphicx}
\newcommand{\code}[1]{{\texttt{#1}}}
\usepackage{verbatim}
\usepackage{xspace}
%\usetheme{default}
%\usetheme{AnnArbor}
%\usetheme{Antibes}
%\usetheme{Bergen}
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS}
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen}
%\usetheme{Hannover}
\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
%\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh}
%\usetheme{Rochester}
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}

% As well as themes, the Beamer class has a number of color themes
% for any slide theme. Uncomment each of these in turn to see how it
% changes the colors of your current slide theme.
\usepackage{hyperref}
\usepackage[utf8]{inputenc}

\usepackage{xcolor}
%\usecolortheme{albatross}
%\usecolortheme{beaver}
%\usecolortheme{beetle}
%\usecolortheme{crane}
%\usecolortheme{dolphin}
%\usecolortheme{dove}
%\usecolortheme{fly}
%\usecolortheme{lily}
%\usecolortheme{orchid}
%\usecolortheme{rose}
%\usecolortheme{seagull}
%\usecolortheme{seahorse}
%\usecolortheme{whale}
%\usecolortheme{wolverine}

%\setbeamertemplate{footline} % To remove the footer line in all slides uncomment this line
%\setbeamertemplate{footline}[page number] % To replace the footer line in all slides with a simple slide count uncomment this line

%\setbeamertemplate{navigation symbols}{} % To remove the navigation symbols from the bottom of all slides uncomment this line
}

\usepackage{graphicx} % Allows including images
\usepackage{booktabs} % Allows the use of \toprule, \midrule and \bottomrule in tables

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title[Laboratoire d'ingénierie cognitive et sémantique (LinCS)]{MediatorBot: A Mediator bot for supporting collaborative E-learning using an Intelligent Tutor System} % The short title appears at the bottom of every slide, the full title is only on the title page

\author{Do Dung Vu \\ Supervisor: Prof. Sylvie Ratt\'e} % Your name

\institute[ETS] % Your institution as it will appear on the bottom of every slide, may be shorthand to save space
{
Département de génie logiciel et des TI \\ % Your institution for the title page
\medskip
\textit{do-dung.vu.1@ens.etsmtl.ca } % Your email address
}
\date{\today} % Date, can be changed to a custom date
\expandafter\def\expandafter\insertshorttitle\expandafter{%
	\insertshorttitle\hfill%
	\insertframenumber\,/\,\inserttotalframenumber}
\begin{document}

\begin{frame}
\titlepage % Print the title page as the first slide 
\end{frame}

\begin{frame}
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\begin{columns}
	\begin{column}{.65\textwidth}
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{column}
	\begin{column}{.35\textwidth}
					\includegraphics[width=25mm]{ETS.png}\\
										\includegraphics[width=25mm]{m2.jpg}\\
															\includegraphics[width=25mm]{korbit.png}
	\end{column}
\end{columns}
\end{frame}

%----------------------------------------------------------------------------------------
%	PRESENTATION SLIDES
%----------------------------------------------------------------------------------------

%------------------------------------------------
\section{Introduction} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\begin{frame}
\frametitle{Forecast}

\begin{center}
	

		\begin{figure}
			\includegraphics[width=65mm]{market2.png}
				
			
		\end{figure}
{\footnotesize 	AI in Education industry 3600 synopsis, 2013 – 2024}
	\begin{thebibliography}{01}
		\bibitem{01}{\tiny  AAAI, IEEE, WEF, IAAIL, Company Annual Reports, Hoovers, Primary Interviews, Global Market Insights}
	\end{thebibliography}

\end{center}




\end{frame}
\begin{comment}
\begin{frame}
\frametitle{History}
\begin{columns}
	\begin{column}{.45\textwidth}
		\begin{figure}
			\includegraphics[width=45mm]{ht12.png}\\
				{\tiny 	\textbf{The history of Intelligent Tutor System (ITS)}}
		\end{figure}



	\end{column}
	
	\begin{column}{.55\textwidth}
		
		
			\begin{figure}
				{\tiny 			AutoTutor system (1)}
			\includegraphics[width=45mm]{autotutor.png}\\
{\tiny 			Korbit (LILA) system (2)}
	
			\includegraphics[width=45mm]{lila.png}\\
	{\tiny Source: (1) autotutor.org
	(2) lilabot.com}


		\end{figure}
	

	\end{column}
\end{columns}
\end{frame}
\end{comment}
\begin{frame}
\frametitle{History}

		
		\begin{figure}
		
			\includegraphics[width=100mm]{history.png}\\
		
				
	\end{figure}
	
{\tiny  \textbf{AutoTuTor system} (2017):  autotutor.org}              {\tiny \textbf{Korbit system }(2018):   lilabot.com}

	
		
	

\end{frame}
\begin{frame}
\frametitle{Intelligence Tutor System (ITS) }
	\begin{block}{ITS main purposes: }
	\begin{itemize}
		\item Help students construct expressions of material as answers to questions and solutions to solve the challenging problems
		\item Ask questions that tap deep levels of reasoning and that involve collaboration
		\item Solve problems that involve deep argumentation
	\end{itemize} 
\end{block}
\end{frame}
\begin{frame}
\frametitle{Context}
\begin{columns}
		\begin{column}{.5\textwidth}
		\begin{figure}
			\includegraphics[width=45mm]{se1.png}
		\end{figure}
		
	\end{column}
	\begin{column}{.5\textwidth}
		\begin{itemize}
			\item Online group learning on a given domain-specific (e.g., statistic)
			\item The group must discuss about a given topic or assignment \footnote{\url{https://mydalite.org/en/}}
			\item The Intelligent Tutor System (ITS) helps Professor to monitor the progress of students and Administrator to encourage the student to study
		\end{itemize}
	\end{column}

\end{columns}

\end{frame}
\begin{frame}
\frametitle{Literature survey}
\begin{itemize}
\item An ITS monitors  students' knowledge, skills, and psychological
characteristics  and response \cite{Sottilare} - 2014
\item Conversational agents have talking heads that
speak, point, gesture, and exhibit facial expressions.
\cite{Johnson2016} - 2016
\end{itemize}
\begin{thebibliography}{01}
	{\tiny 	\bibitem{Sottilare}	[1] Sottilare, R, Graesser, AC, Hu, X, Goldberg, B (Eds.) (2014). Design recommendations
		for intelligent tutoring systems: instructional management, (vol. 2). Orlando:
		Army Research Laboratory
		\bibitem{Johnson2016} [2] 	Johnson, WL, \& Lester, JC. (2016). Face-to-face interaction with pedagogical
		agents, twenty years later. International Journal of Artificial Intelligence in
		Education, 26(1), 25–36. }
\end{thebibliography}

\end{frame}
\begin{frame}
\frametitle{Literature survey}
\begin{itemize}
\item AutoTutor and its progenies [3] help students learn by holding a conversation in natural language - 2016
\item Agent intervention aiming to link students' contributions to previously acquired knowledge can improve both individual and group studying when implemented in the context of a collaborative learning activity in higher education [4]- 2017
\end{itemize}
\begin{thebibliography}{01}
{\tiny 

\bibitem{Graesser2016} [3]	Graesser, AC. (2016). Conversations with AutoTutor help students learn.
International Journal of Artificial Intelligence in Education, 26, 124–132	

\bibitem{Tegos} [4] Tegos,  S.,  \&  Demetriadis,  S.  (2017). Conversational  Agents  Improve Peer  Learning  through  Building  on Prior  Knowledge.Educational Technology \& Society, 20(1), 99–111}
\end{thebibliography}
\end{frame}
\begin{frame}
\frametitle{ Existing problem}
The seven most commonly in Online Learning found in the literature are the following [5]
{\footnotesize \begin{itemize}
		\item (1): the student has conflicts works in the group
		\item (2): the selection of the groups is not good
		\item (3): the students don't have enough group-work skills
		\item (4):  some students want to work alone or become the free-riders
		\item (5):  the possible inequalities of student abilities appears in the group
		\item (6):  some members do not commit to working in the group with their responsibilities
		\item (7): the assessment of individuals within the groups is not fair
\end{itemize}}
\begin{thebibliography}{01}
	\bibitem{Du}{\tiny [5] Jianxia Du, Chuang Wang, Mingming Zhou, Jianzhong Xu, Xitao Fan \& Saosan Lei (2018) Group trust, communication media, and interactivity: toward an integrated model of online collaborative learning, Interactive Learning Environments, 26:2, 273-286,}
\end{thebibliography}


%S. Tegos, \& S. Demetriadis, "Conversational Agents Improve Peer Learning through Building on Prior Knowledge", in Educational Technology \& Society, 20 (1), 99--111, 2017
\end{frame}

\begin{frame}
\frametitle{ Interaction of problems }

Most of these problems above of online group learning are inter-related

\begin{figure}
\includegraphics[width=65mm]{p21.png}
\end{figure}






%S. Tegos, \& S. Demetriadis, "Conversational Agents Improve Peer Learning through Building on Prior Knowledge", in Educational Technology \& Society, 20 (1), 99--111, 2017
\end{frame}
\section{Problem statement} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------



\begin{frame}
\frametitle{ Main problem}

\begin{columns}
	\begin{column}{.55\textwidth}
	\begin{figure}
		\includegraphics[width=65mm]{p22.png}
	\end{figure}
	\end{column}
\begin{column}{.35\textwidth}
	\#3: solved by orientation training from admin \\
	\#6, \#2: solved by professor\\
	\textcolor{blue}{\textbf{\#1: solved by ITS system}}
\end{column}
\end{columns}
\begin{flushleft}
	
\end{flushleft}



\textcolor{blue}{\textbf{$\rightarrow$	We want to solve the problem of student conflicts by using the ITS. }}







%S. Tegos, \& S. Demetriadis, "Conversational Agents Improve Peer Learning through Building on Prior Knowledge", in Educational Technology \& Society, 20 (1), 99--111, 2017
\end{frame}


\begin{frame}
\frametitle{Scenario}
\begin{columns}[onlytextwidth]
	\begin{column}{.45\textwidth}
		\begin{figure}
			\includegraphics[width=.95\textwidth]{pp1}

				\caption{ITS with Mediator}
		\end{figure}
	\end{column}
	\hfill
	\begin{column}{.45\textwidth}
		\begin{figure}
			\includegraphics[width=.95\textwidth]{pp2}
					\caption{Original ITS [6]}

					
		\end{figure}
	
	\end{column}

\end{columns}

\begin{thebibliography}{01}
	\bibitem{Nghe} {\tiny 					[6] N. T-Nghe and L. S-Thieme, "Multi-Relational Factorization Models for Student Modeling in Intelligent Tutoring Systems",  17th International Conference on Knowledge and Systems Engineering (KSE) 2015
	}
\end{thebibliography}

\end{frame}
\begin{frame}


\frametitle{Intuitive Scenario}



\begin{center}
	\includegraphics[width=.9\columnwidth]{cvf1}
\end{center}


\end{frame}


\begin{frame}
\frametitle{MediatorBot}
\begin{center}
	
\end{center}
\textcolor{blue}{\textbf{MediatorBot}  identifies the debated problem, the opportunities for intervention, generates the hints, and answers the related topic question of students to encourage the users to collaborate more effectively in the online group learning with low price in the specific-domain}
\end{frame}








%S. Tegos, \& S. Demetriadis, "Conversational Agents Improve Peer Learning through Building on Prior Knowledge", in Educational Technology \& Society, 20 (1), 99--111, 2017

\begin{comment}
\section{Literature Review} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\begin{frame}
\frametitle{Literature Review}
 \begin{itemize}
{\footnotesize  \item  The important features and chatbot states to be considered in  conversational user
 interface  design  for  specific  domain (e.g., task, duty specification, predict, personalize) in [2]
 	\item A teacher-configurable agent intervention mode 
 	encourages peers to build on their prior knowledge, drawing on the academically productive talk (APT) 	discourse framework is presented in [3]
 	\item The use of conversational agents to scaffold online collaborative learning discussions through an
 	approach called academically productive talk (APT) is investigated in [4].
 	\item A socially capable conversational tutor that supports teams of three (or more) learners in a
 	design task even though there is still
 	room for improvement to match human performance [5]}
 \end{itemize}

\end{frame}
\begin{frame}
\frametitle{Reference}
{\scriptsize \par [1] S. Tegos, \& S. Demetriadis, "Conversational Agents Improve Peer Learning through Building on Prior Knowledge", in Educational Technology \& Society, 20 (1), 99--111, 2017.}
{\scriptsize \par [2] A. Fadhil, "Domain Specific Design Patterns: Designing For Conversational User Interfaces", https://arxiv.org/pdf/1802.09055.pdf}
{\scriptsize \par [3]  S. Tegos, \& S. Demetriadis, "Conversational Agents Improve Peer Learning through Building on Prior Knowledge", in Educational Technology \& Society, 20 (1), pp. 99--111, 2017. }
{\scriptsize \par [4] G. Dyke, D. Adamson, I. Howley and C. P. Rosé, "Enhancing Scientific Reasoning and Discussion with Conversational Agents," in IEEE Transactions on Learning Technologies, vol. 6, no. 3, pp. 240--247, 2013. }
{\scriptsize \par [5] R. Kumar ,H. Ai, J.L. Beuth , C.P. Rosé, "Socially Capable Conversational Tutors Can Be Effective in Collaborative Learning Situations", in: Aleven V., Kay J., Mostow J. (eds) Intelligent Tutoring Systems. ITS 2010.}

\end{frame}
\end{comment}

\section{Motivations} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\begin{frame}
\frametitle{Motivations}
\begin{columns}
	\begin{column}{.55\textwidth}
		\begin{figure}
			\includegraphics[width=55mm]{m1.png}
		\end{figure}

	\end{column}
	
	\begin{column}{.55\textwidth}
		\begin{itemize}
			\item Future state-of-the-art interventions with low price for group online learning
			\item Encourage student collaboration online
			\item Easily scalable 
		
			
		\end{itemize}
	\end{column}
\end{columns}
\end{frame}


\section{Objectives} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\begin{frame}
\frametitle{Objectives}
{\large \textcolor{blue}{\textbf{Main objective:}}} Propose a smart Mediator to support constructive discussion based on the Intelligent Tutor System:

\begin{itemize}
	\item Generate hints to help users solve the topic or problem automatically
	\item    Identify the debated problem
	\item Intervene in the conversation to resolve the conflict
\end{itemize}

\end{frame}



\section{Methodology} % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\begin{frame}
\frametitle{Mediator system}
\begin{figure}
	\includegraphics[width=80mm]{sys2.png}
\end{figure}

\end{frame}
\begin{frame}
\par 	\textbf{(1)  Generate hints to help users solve the topic or problem automatically}
\par \textcolor{gray}{(2) Identify the debated problem }
\par (3) \textcolor{gray}{ Intervene in the conversation to clarify the problem }
\end{frame}

\begin{frame}
\frametitle{Objective 1| Structure}





\begin{center}
			\includegraphics[width=90mm]{ggg.png}
\end{center}

\end{frame}
\begin{frame}

\frametitle{Objective 1 | Methodology | A. Data preprocessing}
\begin{columns}
\begin{column}{.5\textwidth}

(1) Data crawler: crawling data from wikipedia with a given domain-specific (e.g., statistic)\\

(2) Data cleaning: clean the unicode, convert xml equation to latex equation, clean punctuation, split raw text to line by line sentence\\
(3) Dataset: save data to the tsv file with it fields: title, link, content\\
\end{column}
\begin{column}{.5\textwidth}
		\includegraphics[width=50mm]{cr1.png}
\end{column}

\end{columns}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing}
(4) Definition extractor: Extract the description of each concept\\
(5) Definition classification: classify type of definition based on supervisor algorithm (Positive/Negative)\\
$\rightarrow$ Using the \textit{oversampling methodology} to reweight the Positive and Negative samples\\
(6) Definition dataset
\begin{center}
		\includegraphics[width=50mm]{223.png}
\end{center}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition extractor}
\begin{columns}
		\begin{column}{.5\textwidth}
		\includegraphics[width=50mm]{df00.png}
	\end{column}
	\begin{column}{.65\textwidth}
		
		\begin{itemize}
			\item Split raw text dataset to the sentence tokens
			\item Extract the technical keyword acronyms and synonyms
			\item Extract subject (noun phase) $\rightarrow$ Get the keyword (concept)

			\item Get the description of concept
			\item Save the list (dict) description of concept which is called dictionary of definition
		\end{itemize}
	\end{column}

	
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition extractor}

	* Extract the acronyms:  considering the algorithm proposed in [7]\\
	* Extract the synonyms: using the Wikipedia API of direction searching [8]\\
	* Extract the subjects: using the industrial-strength natural language processing frame work [9]
	
	
	\begin{thebibliography}{01}
	{\scriptsize 	\bibitem{Schwartz}[7]  A. Schwartz and M. Hearst (2003) A Simple Algorithm for Identifying Abbreviations Definitions in Biomedical Text. Biocomputing, 451-462	
		
		\bibitem{wikisynonyms} [8]  http://wikisynonyms.ipeirotis.com/api
		\bibitem{spacy} [9] https://spacy.io/}
	\end{thebibliography}
	
	
\end{frame}

\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition extractor | Examples}
{\small \textbf{* Synonyms:}  Linear regression model \\
	\code{'Linear modeling','Regression coefficient','Linear Regression', 'Regression coefficients','Regression line','Linear weights','Multiple linear regression','Line regression','Linear regression model','Linear trend','Multi-linear regression','Linear fit','Line of regression','Linear regression'} \\
\textbf{* Acronyms:} RNN\\
\code{'recurrent neural network','random neural network'} \\
\textbf{* Tree of sentence:} \\}
		\includegraphics[width=100mm]{spa.png}
\end{frame}

\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition classification}
\begin{columns}

	\begin{column}{.55\textwidth}
		\begin{itemize}
			\item Extract the features $\rightarrow$ score table
			\item Save the score table to the definition dataset
			\item Classify the Positive/Negative definition based on logistic regression
			\item Save the classification model
		\end{itemize}
	
	\end{column}
	\begin{column}{.55\textwidth}
	\includegraphics[width=50mm]{dc3.png}
\end{column}
	
	
\end{columns}
\begin{center}
	
\end{center}
\textcolor{blue}{\textbf{$\rightarrow$ Create the resources for Hints generator}}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition classification}
{\tiny \begin{table}[]
	\begin{tabular}{|l|l|lll}
		\cline{1-2}
		\textbf{Features}             & \textbf{Summary}              &  &  &  \\ \cline{1-2}
		\code{length\_of\_keyword}  & the number words in the keyword    &  &  &  \\ \cline{1-2}
		\code{length\_of\_description} & the number words in the description &  &  &  \\ \cline{1-2}
		\code{score\_keyword}          & inverse document frequency of keyword          & &  &  \\ \cline{1-2}
		\code{score\_description}          & inverse document frequency of concepts description          & &  &  \\ \cline{1-2}
		
		\code{ner\_in\_description}          & name of entity recognition within the description        & &  &  \\ \cline{1-2}
		
		
		\code{coreference\_in\_description}          & compute the coreference resolution score         & &  &  \\ \cline{1-2}
		
		\code{type\_of\_word}          & recognize type of word (verb, noun, etc.,)        & &  &  \\ \cline{1-2}
		
		\code{non\_of\_word}          & recognize the none of word (symbol, number, etc.,)        & &  &  \\ \cline{1-2}
		\code{pronouns\_rate}          &  the rate of $\frac{pronouns}{nouns}$  & &  &  \\ \cline{1-2}
		\code{keyword\_rate}          &  the rate of $\frac{keyword\_position}{length\_of\_description}$  & &  &  \\ \cline{1-2}
		\code{perplexity}          & the real value of perplexity of desciption  & &  &  \\\cline{1-2}
		\code{likelihood\_score\_description}          & \begin{tabular}[c]{@{}l@{}}the log-likelihood probability score of description\\ based on sum of probability term by using language \\model based on RNN \end{tabular} & &  &  \\ \cline{1-2}
	\end{tabular}
	\caption{Features of definition}
\end{table}}
\end{frame}

\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition classification| Experiment Result}



\begin{columns}
		\begin{column}{.55\textwidth}
		\includegraphics[width=70mm]{Figure_1.png}
	\end{column}
	\begin{column}{.35\textwidth}
		\begin{itemize}
		{\scriptsize 	\item Dataset: 59211 definitions /  2452 articles
		\item Number of positive definitions: 2452
		\item Number of negative definitions: 56759}
		\end{itemize}
		
	\end{column}

	
	
\end{columns}



\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | B. Definition processing | Definition classification| Example}
{\tiny \begin{table}[]
		\begin{tabular}{|l|l|l|l|l|l|l|}
			\hline
			key & definitnion & label & \begin{tabular}[c]{@{}l@{}}score\\ keyword\end{tabular} & \begin{tabular}[c]{@{}l@{}}score\\description\end{tabular} & ... & \begin{tabular}[c]{@{}l@{}}likelihood\\ score \\ description\end{tabular} \\ \hline
			\begin{tabular}[c]{@{}l@{}}Linear\\   regression\end{tabular}   & \begin{tabular}[c]{@{}l@{}}In statistics, linear   regression \\is a linear approach to \\ modelling the relationship between a \\scalar response (or dependent variable)\\  and one or more explanatory\\ variables  (or independent variables).\end{tabular}              & \textbf{\textcolor{blue}{Positive }}     & 14.58                                                        & 130.53                                                                     & ...                & 10.64                                                                                     \\ \hline
			\begin{tabular}[c]{@{}l@{}}linear \\regression\\   models\end{tabular}	&  \begin{tabular}[c]{@{}l@{}}The numerical methods for  \\linear least squares are\\ important because linear regression\\ models are among   the\\ most important types of\\ model, both as formal statistical\\ models and   exploration of data-sets.\end{tabular}            &     \textbf{Negative }    &  20.78                                                                 &                                   146.77                                     &   ...  &                         10.49                                                               \\ \hline
			\begin{tabular}[c]{@{}l@{}} local\\ linear \\regressions\end{tabular}	&  \begin{tabular}[c]{@{}l@{}}local linear regressions are\\ preferred because they have better bias \\properties and have better convergence.\end{tabular}            &     \textbf{Negative }  &  25.93                                                               &                                    85.57                                    &   ...  &                          8.04                                                              \\ \hline
		\end{tabular}
\end{table}}

\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | C. Hint generation}
(7) Hints discriminator: classify level of hints based on the student profiles \\
(8) Question recognition: recognize question of student\\
(9) Answer recognition: recognize answer of student \\

(10) Hints generator: generate hint based on hint types, level, and language model \\
\begin{center}
	
\begin{center}
		\includegraphics[width=50mm]{hf3.png}
\end{center}
\end{center}
\end{frame}


\begin{frame}
\frametitle{Objective 1 | Methodology | C. Hint generation | Hints discriminator }
\begin{columns}
	
	\begin{column}{.55\textwidth}
		\begin{itemize}
			\item Classify the students' level based on their profile (e.g., the result of the initial exam, the number thumb up/down of a student, etc.,)
			\item Discriminate hints based on level of student
			
		\end{itemize}
		
	\end{column}
	\begin{column}{.35\textwidth}
		\includegraphics[width=18mm]{hd1.png}
	\end{column}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | Hint generating | Question \& Answer recognition }
(8) Question recognition: Recognize the users' questions\\
(9) Answer recognition: Recognize the users' answers
\begin{center}
		\includegraphics[width=55mm]{qa3.png}
\end{center}
\end{frame}
	

\begin{frame}
\frametitle{Objective 1 | Methodology | C. Hint generation| Hint generator}
	\includegraphics[width=90mm]{hints3.png}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | C. Hint generation| Hint generator| Construct hints}
 * Type of questions: (a) definition, (b) definition \& explanation, (c)contrast, (d)explanation, and (e) deeper understanding (E.g.,
 \begin{itemize}
 {\scriptsize 	\item (a) “What are non-parametric models?” 	
 	\item (b) "... Is this a classification or a regression model? Explain why?”
 	\item (c) "What is the difference between classification and regression?” 	
 	\item (d) “Why is linear regression a parametric model?”
 	\item (e) “What assumptions are usually made about the examples in a dataset?”
 	}
 \end{itemize}
* The hints are phrased in the form of "Think about X" or "Consider X" where X is the part of expectation answer. \\

\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | C. Hint generation| Hint generator| Construct hints}
* Using Linear regression model based on the features: 
{\scriptsize  \begin{table}[]
	\begin{tabular}{|l|l|lll}
		\cline{1-2}
		\textbf{Features}             & \textbf{Summary}              &  &  &  \\ \cline{1-2}
		\code{length\_of\_hint}  & the number words in the hint     &  &  &  \\ \cline{1-2}
		\code{overlap\_question\_hint} & the rate of overlap between question and hint &  &  &  \\ \cline{1-2}
		\code{score\_keyterm}          & inverse document frequency of keyterm in hint          & &  &  \\ \cline{1-2}
		\code{keyhint\_keyquestion\_ratio}          & the ratio of $\frac{number\_of\_keyhint}{number\_of\_keyquestion}$     &  &  &  \\ \cline{1-2}
		\code{topic\_overlap}          & content overlap between the question and hint     &  &  &  \\ \cline{1-2}
		
		\code{pronouns\_rate}          &  the rate of $\frac{pronouns}{nouns}$ in hint  & &  &  \\ \cline{1-2}
		\code{keyword\_rate}          &  the rate of $\frac{keyword\_position}{length\_of\_hint}$  & &  &  \\ \cline{1-2}
		\code{perplexity}          & the real value of perplexity of hint  & &  &  \\ \cline{1-2}
		\code{ner\_in\_hint}          & name of entity recognition within the hint        & &  &  \\
		 \cline{1-2}
		 	\code{score\_of\_hint}          & \begin{tabular}[c]{@{}l@{}}the log-likelihood probability score of hints\\ based on sum of probability terms  by using language \\model based on RNN\end{tabular}       & &  &  \\
		 		 \cline{1-2}
	\end{tabular}
	\caption{Features of hints}
	\label{tab:3}
\end{table}}

\end{frame}
\begin{frame}
\frametitle{Objective 1 | Methodology | C. Hint generation| Hint generator| Construct hints| Example}


{\tiny \textbf{Question:\\}
\colorbox{green!30}{\begin{tabular}[c]{@{}l@{}}You are given a dataset of images of wildlife in Africa.\\ You are tasked with building a model which can identify animals in the images. \\
Is this a regression or classification problem? Explain why?\end{tabular}    }}\\
{\tiny \textbf{Answer:\\}
\colorbox{blue!30}{\begin{tabular}[c]{@{}l@{}}It is the regression problem because the animal is the independent entity in the africa\end{tabular}    }}\\
{\tiny \textbf{Hints:}}
{\tiny \begin{itemize}
	\item Recall that each animal is a class.
	\item Recall that each animal is a discrete class.
	\item Consider that each animal is a separate class.
	\item Consider that we are choosing between a set of categories.
	\item Think about the following: we are choosing between discrete-valued output variables.
	\item Consider that each image can contain several animals, and therefore the model must predict the existence of each type of animal.
	
\end{itemize}}


\end{frame}

\begin{frame}
\frametitle{Evaluation result}
\begin{center}
	
	
	
	Example of Cohen Kappa for hints generator: \\
	\includegraphics[width=60mm]{kohen.png} 
	
	
\end{center}
Kappa:46\% $\rightarrow$ moderate agreement
\end{frame}
\begin{comment}
\begin{frame}
\frametitle{Objective 1 $|$ (A) Pattern detection}
\par + Extract the subject or object  of each sentences in the conversation to get the candidate pattern\footnote{https://spacy.io/} based on syntax tree 
\par + Compute the tf-idf score of each pattern
	
\begin{equation}
W^{PT} = \prod_{k}{TFIDF(term_k)}
\end{equation}


\end{frame}
\begin{frame}
\frametitle{Objective 1 $|$ (B) Lexical similarity}
 The  lexical  similarity  score  can  be  
calculated using their cosine similarity:

\begin{equation}
W^l = cos_{sim}(m_i,m_j)
\end{equation}
$m_i, m_j$ are the message $i^{th}, j^{th}$ without stop words, prepositions, pronouns, adjective, modify
\end{frame}
\begin{frame}
\frametitle{Objective 1 $|$ (C) Poster trustworthiness}
To  determine the trustworthiness of a person, we studied the responses to their messages throughout the entire  corpus
\begin{equation}
W^p = \frac{count(positive_{feedback}(person_k))}{count(feedback(person_k))}
\end{equation}
$\rightarrow$ poster trustworthiness  score  indicates  the  importance  of  message  $m_i$

\end{frame}
\begin{frame}
\frametitle{Objective 1 $|$ (D) Message act analysis}
We  compute  the  strength  of  each  speech  act  in a  
generative  way,  based  on  the  users  and their trustworthiness.  
\begin{equation}
W_{SA} = \frac{\sum_{person_k}{W^p(person_k)}}{\sum{person_k}}
\end{equation}

\end{frame}
\begin{frame}
\frametitle{Objective 1 $|$ (E) Acronyms investigation}


 Identify  “short  form”,  “long 
	form” pairs where there exists a mapping (of any kind) from characters in the short 
	form to characters in the long form [6]
\begin{itemize}
	\item  short 
	form:	methyl methanesulfonate sulfate (MMS)
	\item long form: Gcn5-related N-acetyltransferase (GNAT)
\end{itemize}
\begin{center}
\begin{equation}
  W^A = \begin{cases}
1, \text{if Idenfified "short form" or "long form"} \\
0, otherwise
\end{cases}
\end{equation}
\end{center}
{\tiny [6] A. Schwartz and M. Hearst (2003) A Simple Algorithm for Identifying Abbreviations Definitions in Biomedical Text. Biocomputing, 451--462}

%{\tiny [6] Y. Park, and R.J. Byrd, “Hybrid Text Mining for Finding Abbreviations and Their Definitions” Proceedings of the 2001 Conference on Empirical Methods in Natural Language Processing , Pittsburgh, PA, June 2001: 126--133 }


\end{frame}
\begin{frame}
\frametitle{Objective 1 $|$ (F) Conversation Focus Detection}
\begin{itemize}
	\item {Classify the problem in the conversation
		\begin{itemize}
			\item Detect inappropriate content in text [7]
			\item Detect Emotion of users in text [8]
		\end{itemize}
	}
	\item Get the score of each features, dectect the conversation forcus
\end{itemize}
$\rightarrow$ Identify opportunity of intervention

\begin{flushleft}
	\par {\tiny [7] H. Yenala, A. Jhanwar, M. K. Chinnakotla, and J. Goyal, "Deep learning for detecting inapporpriate content in text", in International Journal of Data Science and Analytics (2018) 6:273--286}
	\par {\tiny [8] U. Gupta, R. Srikanth, A. Chatterjee, and P. Agrawal, "A sentiment-and-semantics-based approach for emotion detection in textual converations, in arXiv:1707.06996v4 [cs.CL] 30 Mar 2018 }

\end{flushleft}
\end{frame}
\begin{frame}
\frametitle{Objective 1 | (G) Evaluation the intervention}
\begin{itemize}
\item Using Logistic regression to get the intervention 
\item Output contains: name of problem, decision of intervention 
\end{itemize}


\end{frame}

\end{comment}


\begin{frame}
\par 	\textcolor{gray}{(1)  Generate hints to help users solve the topic or problem automatically}
\par \textbf{(2) Identify the debated  problem }
\par (3) \textcolor{gray}{ Intervene in the conversation to clarify the problem }
\end{frame}
\begin{frame}
\frametitle{Objective 2 | Structure}


\begin{center}
	\includegraphics[width=80mm]{33.png}
\end{center}

\end{frame}
\begin{frame}
\frametitle{Objective 2 | Methodology | Data preprocessing}



\begin{columns}
	
	\begin{column}{.55\textwidth}
\textbf{	(1) Data crawler}: crawling data from stackoverflow (e.g., statistic)\\

\textbf{	(2) Data cleaning}: Clean content: clean unicode, equation over the conversation\\
\textbf{	(3) Conversation dataset}: save the conversation dataset\\
	\end{column}
	\begin{column}{.45\textwidth}
		\includegraphics[width=40mm]{dsf.png}
	\end{column}
	

\end{columns}
\begin{center}
	
\end{center}



\end{frame}


\begin{frame}
\frametitle{Objective 2 | Methodology}
\textbf{(4) Association rules [10]}: find the interesting association or correlation relationship between dominant words  [10] \\


\begin{columns}
	\begin{column}{.55\textwidth}
		\includegraphics[width=50mm]{AR_1.png}
		$X,Y$: word pair
		\begin{thebibliography}{01}
			\bibitem{Paryasto}{\tiny 	[10] A. Alamsyah, M. Paryasto, F. J. Putra, R. Himmawan, "Network text analysis to summarize online converstations for marketing intelligence efforts in telecommunication industry", in 2016 ICoICT}
		\end{thebibliography}

	\end{column}
	\begin{column}{.55\textwidth}
	\begin{itemize}
		\item \underline{$Support$:} how frequently the itemset appears in the dataset.
		
		
		\item $Confidence$: how often the rule has been found to be true.
		
		
		\item $Lift$: the ratio of the observed support to that expected if X and Y were independent
		
	\end{itemize}

	\end{column}
\end{columns}


\end{frame}


\begin{frame}
\frametitle{Objective 2 | Methodology}
\begin{columns}
	\begin{column}{.35\textwidth}
		\includegraphics[width=40mm]{nw.png}\\
{\scriptsize 	\textbf{An example of text network}}
	\end{column}

	\begin{column}{.60\textwidth}
(\textbf{5) Construct network text of dominant word}: include\underline{ weighted edge} result for association rule processes\\
\textbf{(6) Network analysis:} create context, keyword, and sense from network text\\
$\rightarrow$ employ centrality to find the most influential words in the networks and modularity to find words cluster/ groups in the network \\

	\end{column}
\end{columns}
\end{frame}
\begin{frame}
\frametitle{Objective 2 | Methodology}
+ Using K-means algorithm to cluster and  store Association Rules without favoring or excluding any evaluation measurement of an association rule.[11]\\
+ Using the Elbow-method to identify the best value of K for K-means cluster [12]

$\rightarrow$\textbf{(7) Identify conflict problem:} get the conflict problem related to the topic by mapping conversation to clusters analysis\\

\begin{thebibliography}{01}
{\tiny 	\bibitem{Dahbi} [11] A. {Dahbi}, M. {Mouhir}, Y. {Balouki} and T. {Gadi},"Classification of association rules based on K-means algorithm", in 2016 4th IEEE International Colloquium on Information Science and Technology (CiSt)}
{\tiny 	\bibitem{Dahbi} [12] Kodinariya, Trupti M. and Raj Makwana. “Review on determining number of Cluster in K-Means Clustering.” Volume 1, Issue 6, November 2013 International Journal of Advance Research in 	Computer Science and Management Studies.}
\end{thebibliography}

\end{frame}


\begin{comment}
\begin{frame}
\frametitle{Objective 2 $|$ (A) Definitions extractor}

\begin{itemize}
	\item Extract the definition of  concept from the open source meta-data (e.g., wikipedia, reddit) 
	\item Scrape the definitions of concept from some domain--specific glossary webpage (Breadth First Search) \footnote{https://www.geeksforgeeks.org}
	\item Generate the definition of concept from the other sources which cite this one as a reference
	\item Make the scoring model to evaluate the kind of definitions, SVM is utilized to classify the descriptions
	
\end{itemize}


\end{frame}
\begin{frame}
\frametitle{Objective 2 $|$ (B) Hints generator}
\begin{itemize}
	\item Get the keyword and description from definition extractor
		\item Classify the type of hints based on types of questions (definition, explanation,  definition+explanation, 2 (or more) definitions contrasting each other, list of properties.) by using SVM
			\item Create the auxiliary questions by considering the  keywords in the users' question 
				\item The strategy for now will rely on the comparison of the reference solutions to the question and detection of the bits of the reference solution that can be presented to the users with the template “Think (about) X” / “Consider X” / “Note that X”
\end{itemize}



\end{frame}

\begin{frame}
\frametitle{Objective 2 $|$ (C) Questions and Answers generator}

\begin{itemize}
	\item Each triple consists of a subject, a predicate, and an object. Subjects and objects represent the definition of a concept based on the keywords
	\item Extract the relationship holding between subject and object
	\item Parse data to the types of question to generate the questions
	\item The answer is then generated by taking as input the generated question, the sentence or paragraph used for generating the question, other relevant unstructured data and possibly the user’s answer based on Euclidean distance.
\end{itemize}



\end{frame}

\begin{frame}
\frametitle{Objective 2 $|$ (D) Evaluation of the score of reference}

\par (1) We believe that BLEU
are reasonable evaluation metric: The BLEU [9] metric ranges from 0 to 1. Few translations will attain a score of 1 unless they are identical to a reference translation
\par (2) We use the users experiment testing to evaluate the output




\begin{flushleft}
	{\tiny [9] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, "BLEU: A method for automatic evaluation of machine translation, in Proceedings of the 40th Annual Meeting of the Asoociation for Computational Linguistics (ACL), Philadelphia, July 2002, pp. 311--318}
\end{flushleft}
\end{frame}
\begin{frame}
\par 	\textcolor{gray}{(1)  Generate hints to help users solve the topic or problem automatically}
\par \textcolor{gray} {Identify the debated or clarify the problem }
\par (3) \textbf{ Intervene in the conversation to clarify the problem: identify the opportunities for intervention, answer the related topic question of users }
\end{frame}
\begin{comment}
\begin{frame}
\frametitle{Objective 2}

\begin{columns}[T]
	\begin{column}{.5\textwidth}
		\includegraphics[width=55mm]{f21.jpg}
	\end{column}
	\begin{column}{.5\textwidth}
		
		\begin{itemize}
			\item Step 1: Get the raw text data from the user conversation
			\item Step 2: Process text go extract and compute the score of features 
			\item Step 3: Adapt word sense disambiguation
			\item Step 4: Evalue the semantic relateness and coreference resolution
			\item Step 5: Get the meaning of the sentence
		\end{itemize}
		
	\end{column}
\end{columns}
\end{frame}

\begin{frame}
\frametitle{Process of creating model}
\begin{figure}
	\includegraphics[width=.8\linewidth]{Spacy.png}
\end{figure}

\begin{itemize}
	\item  Our models are \textbf{statistical} and every "decision" are made by \textbf{prediction}
	\item This precision is based on the examples the model has seen during training
	\item We give the model feedback on its prediction in the form of an \textbf{error gradient} of the\textbf{ loss function} that calculates the difference between the training example and the expected output
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Techniques}
\textbf{Scoring model for definitions (Preprocessing)} 
\begin{columns}[T]
	\begin{column}{.5\textwidth}
		\begin{figure}

				\includegraphics[width=50mm]{u3.png}
		
				\includegraphics[width=30mm]{testplot.png}

		\end{figure}
	\end{column}
\begin{column}{.5\textwidth}
	\begin{itemize}
		\item Create the features for the scoring model
		\item Compute the score for these ones
		\item Using the SVM algorithm to classify the kind of concept descriptions
		
	\end{itemize}
$\leftarrow$ E.g., extract definitions from wikipedia
\end{column}

\end{columns}


\end{frame}

\begin{frame}
\frametitle{Techniques}
\textbf{Features preprocessing} 
\begin{columns}[T]
	\begin{column}{.5\textwidth}
		
		\begin{itemize}
			\item Recognize the subject, verb, object in a given sentence
			\item Recoginze noun, adj, adv, preposition of a sentence
			\item Recognize the entities in a sentence
			\item Recognize the coreference of a sentence
		\end{itemize}
	\end{column}
	\begin{column}{.6\textwidth}
		
		\includegraphics[width=65mm]{f5.jpg}
		
		
	\end{column}
\end{columns}



\begin{flushleft}
	$\rightarrow$ \textit{create the table of features }
\end{flushleft}

\end{frame}

\begin{frame}
\frametitle{Dataset}
\begin{center}
	\textbf{Crawl dataset}\\
	\includegraphics[width=80mm]{dataset.png}
\end{center}
\end{frame}


\begin{frame}
\frametitle{Methodology}
\textbf{Objective 2: Proper intervention}\\

\begin{center}

	\includegraphics[width=80mm]{interact5.png}
	
\end{center}
\end{frame}
\end{comment}
%keep the title consistence for every section
%put everything label to the block on the diagram
%general diagram
%come to see what is going on in the forum to extract the pattern
%using expert to create the table of evaluation (small training dataset) for opportunies
% what the computer rejected
%____ generating -> give it to the user try to use, and get feedback

%BLUE,  to evaluate the quality of output
%semi-automatic

%what is helpful (say yes or not)
%the professor test first, (OB1: use the data professor interact with student --> converstation -> what kind of intevention....)

\begin{frame}
\par 	\textcolor{gray}{(1)  Generate hints to help users solve the topic or problem automatically}
\par \textcolor{gray}{(2) Identify the debated  problem }
\par (3) \textbf{ Intervene in the conversation to clarify the problem }
\end{frame}
\begin{frame}
\frametitle{Objective 3| Structure}


\begin{figure}
	\includegraphics[width=75mm]{58.png}	
	
	
	

\end{figure}

\end{frame}
\begin{frame}
\frametitle{Objective 3 | Methodology | Sentiment analysis}
\begin{columns}
	
	\begin{column}{.5\textwidth}
\begin{figure}
	\includegraphics[width=48mm]{sent3.png}	
	
\end{figure}
\end{column}


\begin{column}{.5\textwidth}
{\scriptsize \begin{itemize}
	\item Listening the conversation
	\item Using SVM in classifying the sentiment of content
	\item Cumulate the sentiment of question, answer, and comment for evaluating the sentiment of conversation
\end{itemize}}


\begin{thebibliography}{01}
	
	{\tiny \bibitem{Rafferty}  [13] M. Marneffe, A. N. Rafferty, and C. D. Manning. 2008. Finding contradictions in text. In Proc. ACL}
	{\tiny 	\bibitem{Dahbi} [14] L. Ling, S. Larsen, "Sentiment Analysis on Stack Overflow with Respect to Document Type and Programming Language", KTH ROYAL INSTITUTE OF TECHNOLOGY, 2018}


\end{thebibliography}



\end{column}

\end{columns}	
\end{frame}
\begin{frame}
\frametitle{Objective 3 | Methodology | Sentiment analysis | Preprocessing}
1. Clean the data by removing the html tags, urls  \\
2. Use the Senti4SD [15] to classify the dataset \\
\begin{thebibliography}{01}
{\tiny \bibitem{Calefato} [15] Calefato, F., Lanubile, F., Maiorano, F., Novielli N. (2018) "Sentiment Polarity Detection for Software Development," Empirical Software Engineering, 23(3), pp:1352-1382}
\end{thebibliography}
\end{frame}



\begin{frame}
\frametitle{Objective 3 | Methodology | Intervention}
\begin{columns}
	
	\begin{column}{.45\textwidth}
		(2) Identifiable opportunities of intervention: analysis the serious of conversation and conflict problem \\
		
		
		(3) Clarified problem of conversation: give the right hints\\
	
	\end{column}
	\begin{column}{.55\textwidth}
		\includegraphics[width=50mm]{tsv3.png}	
	\end{column}
	
\end{columns}
\end{frame}


\begin{frame}
\frametitle{Evaluation measurement}
Because this is the conversation between Human and machine, so we prefer to use the users' experiment test to get feedback score in range (1,5) and expert recommendations.


\end{frame}

\begin{frame}
\frametitle{Evaluation | Approach }


\begin{columns}[onlytextwidth]
	\begin{column}{.45\textwidth}
		\begin{figure}
			\includegraphics[width=.8\textwidth]{lsm}
		\end{figure}
	\begin{center}
			{\tiny 	Source: https://www.jpattonassociates.com/}
	\end{center}
	\end{column}
	\hfill
	\begin{column}{.45\textwidth}
		\begin{figure}
			\includegraphics[width=.6\textwidth]{mvp}
		\end{figure}
	\begin{center}
			{\tiny 	Source: https://quickleft.com}
	\end{center}
	\end{column}
\end{columns}

{\scriptsize *  We evaluate our system by using the user experiments testing. 
	\begin{itemize}
		\item students' experiments
		\item professor recommendations
	\end{itemize}
*  Users: students at the class offline, students on LILA \footnote{https://lilabot.com }, friends (if Research Ethic Board (REB) is approved) or Amazon Mechanical Turk\footnote{https://www.mturk.com}}



\end{frame}

\begin{frame}
\frametitle{Evaluation | Environment}
\begin{figure}
	\includegraphics[width=.8\textwidth]{ue1.png}
\end{figure}
\begin{itemize}
	\item (1) Use the Facebook messenger API\footnote{https://developers.facebook.com} to set up the conversation environment
	\item  (2) Set up the flask server for local host 
	\item  (3) Process the conversation with the given bot memory and knowledge 
\end{itemize}

\end{frame}
\begin{frame}
\frametitle{Evaluation | Environment}
\begin{itemize}
	\item  (4) Feedback statistic evaluation (\url{https://docs.gogle.com/forms/u/0/ })
\item  (5) Using Cohen's Kappa [16] for evaluating the agreement of human and machine experiment 
\end{itemize}
\begin{thebibliography}{01}
{\tiny 	\bibitem{citekey} [16] {J. {Toppi} and N. {Sciaraffa} and Y. {Antonacci} and A. {Anzolin} and S. {Caschera} and M. {Petti} and D. {Mattia} and L. {Astolfi}}, "Measuring the agreement between brain connectivity networks", in 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}
\end{thebibliography}


\end{frame}


\begin{frame}
\frametitle{Achievements}
(1) 3 years Mitacs accelerate grant for Natural Language Generation for Intelligent Tutoring Systems \\
\begin{center}
	
\end{center}
(2) Directly apply the results to KORBIT (LILA) pipeline  at Ai-educate Inc \\
 \textcolor{gray}{Because of the NDA conditions, the experiment results have to be confidential at least 1 year, so it is not published now even the student McGills' feedbacks are good}



\end{frame}
\begin{comment}
\begin{frame}
\frametitle{Achievements}
+ Experiment setup: graduate and undergraduate students from McGill COMP-551 from 6/2/2019 - 8/2/2019

{\scriptsize \begin{table}[]
	\begin{tabular}{|l|l|l|}
		\hline
		& \begin{tabular}[c]{@{}l@{}}Human-Generated\\  Hints\end{tabular} & \begin{tabular}[c]{@{}l@{}}Machine-Generated \\ Hints\end{tabular} \\ \hline
		Sessions (Users)                                                                                                                                                    & {\color[HTML]{333333} 36}                                        & {\color[HTML]{333333} 36}                                          \\ \hline
		\begin{tabular}[c]{@{}l@{}}Number of times text-based hint \\ was shown (including the times it\\  was shown after the user clicked \\ “I don’t know”)\end{tabular} & 30 (100\%)                                                       & 19 (100\%)                                                         \\ \hline
		\begin{tabular}[c]{@{}l@{}}Number of times users improved \\ their next solution attempt after \\ hint was shown\end{tabular}                                       & 8 (26.67\%)                                                      & \textbf{8 (42.11\%)                                                      }  \\ \hline
		\begin{tabular}[c]{@{}l@{}}Number of times users gave a \\ “CORRECT” next solution attempt \\ after hint was shown\end{tabular}                                     & 5 (16.67\%)                                                      & \textbf{6 (31.58\%)                                                        }\\ \hline
	\end{tabular}
\end{table}}
\textit{Source: Ai-educate}
\end{frame}
\end{comment}

\begin{comment}
\subsection{} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks

\begin{frame}
\frametitle{Introduction}
\begin{columns}[T]
	
\begin{column}{.45\textwidth}
	\begin{figure}
		\includegraphics[width=50mm]{sound_processing_courtesy_asha.png}
		https://www.autismspeaks.org
	\end{figure}
\end{column}

\begin{column}{.6\textwidth}
	\begin{itemize}
		\item Auditory processing is defined as what we do with what we hear \footnote{Katz  \&  Tillery,  2004}
		\item Auditory Processing Disorder (APD) is a condition where someone has normal hearing, but the auditory system does not faithfully bring information to the brain \footnote{https://www.sac-oac.ca}
		\item \textbf{Approximate 2-4\% of school age children have APD} \footnote{http://www.ementalhealth.ca/}
		\item Autism and auditory processing disorders often overlap\footnote{https://www.autismspeaks.org}
	\end{itemize}
\end{column}
\end{columns}


\end{frame}
\begin{frame}
\frametitle{Challenging}
\includegraphics[width=120mm]{mind.jpg}

\end{frame}
\begin{frame}
\frametitle{Objectives}
Propose an AI model (virtual assitance) named \textcolor{blue}{\textbf{MedicBot}} to assit in diagnosing, monitoring, and training of the children with APD problem with low price, healthy, and convinent
\begin{columns}
	\begin{column}{.3\textwidth}
\begin{center}
		\includegraphics[width=30mm]{MedicBot.png}
	
\textbf{	MedicBot}
\end{center}

	\end{column}
\begin{column}{.7\textwidth}


\begin{itemize}
	\item Diagnose APD symptoms based on \textcolor{blue}{conversation} with the considered children
	\item Create a Training Therapy Model Assitance (adaptable)
	\item Build the Reinforcement Learining (RL) Model to monitor the progress of APD treatment
\end{itemize}



\end{column}
\end{columns}
\end{frame}

\section{Problem statement}
\section{Literature survey}
\section{Motivations}
\section{Objectives}
%------------------------------------------------
\section{Methodology } % Sections can be created in order to organize your presentation into discrete blocks, all sections and subsections are automatically printed in the table of contents as an overview of the talk
%------------------------------------------------
\subsection{} % A subsection can be created just before a set of slides with a common theme to further break down your presentation into chunks

\begin{frame}
	\frametitle{Methodology}
	\begin{itemize}
		\item Analysis  the  given  APD  symptoms  by  speech  	
		recognition  based  on  Deep  learning
		
		\item \color{gray} Analysis  the  given  APD  therapy  and  recommend  the
		
		treatment  to  the  APD  children.  Apply  a  natural  language
		
		processing  (NLP)  to  generate  sentences  and  exploit  Deep
		
		learning  to  understand  the  context  of  the  speech
		
		\item Monitoring  the  process  of  APD  treatment  by  using  speech  analysis  based  on  Deep
		
		learning
	\end{itemize}

\end{frame}


%------------------------------------------------

%------------------------------------------------
\begin{frame}
\frametitle{Implementation}
\includegraphics[width=120mm]{process.png}
\end{frame}

\begin{frame}
\frametitle{Techniques}
\textbf{Convert speech to text}
\begin{columns}[T]
		\begin{column}{.5\textwidth}
		
		\begin{itemize}
			
		\item	\textbf{Acoustic modeling} represents the relationship between linguistic units of speech and audio signals.
		\item	\textbf{Language modeling} matches sounds with word sequences to help distinguish between words that sound similar.
			
		\end{itemize}
		
	\end{column}
	\begin{column}{.5\textwidth}
				\includegraphics[width=65mm]{f1.jpg}
	\end{column}

\end{columns}
 {\small We evaluated the quality of output by using two factors:\footnote{https://pypi.org/project/SpeechRecognition/}\\

\textbf{Accuracy} and \textbf{Speed} }

\end{frame}

%------------------------------------------------


\begin{frame}
\frametitle{Techniques}
\textbf{Proposal for the objective 1 solution}
\begin{columns}[T]
	\begin{column}{.5\textwidth}
		\includegraphics[width=55mm]{f21.jpg}
	\end{column}
	\begin{column}{.5\textwidth}
		
		\begin{itemize}
			\item Step 1: Get the raw text data from the user conversation
			\item Step 2: Process text go extract and compute the score of features 
			\item Step 3: Adapt word sense disambiguation
			\item Step 4: Evalue the semantic relateness and coreference resolution
			\item Step 5: Get the meaning of the sentence
		\end{itemize}
		
	\end{column}
\end{columns}

\end{frame}
\begin{frame}
\frametitle{Dataset}
\textbf{Open Dataset}
\begin{itemize}
{\scriptsize   	\item (NLVR) A Corpus of Natural Language for Visual Reasoning, 2017
	\item (MS MARCO) MS MARCO: A Human Generated MAchine Reading COmprehension Dataset, 2016
	\item (NewsQA) NewsQA: A Machine Comprehension Dataset, 2016 
	\item (SQuAD) SQuAD: 100,000+ Questions for Machine Comprehension of Text, 2016
\item 	(GraphQuestions) On Generating Characteristic-rich Question Sets for QA Evaluation, 2016 
\item 	(Story Cloze) A Corpus and Cloze Evaluation for Deeper Understanding of Commonsense Stories, 2016 
\item 	(Children's Book Test) The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations, 2015 
\item 	(SimpleQuestions) Large-scale Simple Question Answering with Memory Networks, 2015
\item 	(WikiQA) WikiQA: A Challenge Dataset for Open-Domain Question Answering, 2015
\item 	(CNN-DailyMail) Teaching Machines to Read and Comprehend, 2015 
\item 	(QuizBowl) A Neural Network for Factoid Question Answering over Paragraphs, 2014 
\item 	(MCTest) MCTest: A Challenge Dataset for the \item Open-Domain Machine Comprehension of Text, 2013 
\item (QASent) What is the Jeopardy model? A quasisynchronous grammar for QA, 2007 }
\end{itemize}


\end{frame}
\begin{frame}
\frametitle{Dataset}
\begin{center}
	\textbf{Crawl dataset}\\
\includegraphics[width=80mm]{f9.jpg}
\end{center}
\end{frame}

\begin{frame}
\frametitle{Dataset}
\textbf{Paraphase database (PPDB)}
\begin{itemize}
	\item \textbf{PPDB}\footnote{http://paraphrase.org} is an automatically extracted database containing millions paraphrases in 16 different languages. 
	\item 
	The goal of PPBD is to improve language processing by making systems more robust to language variability and unseen words. 
	\item The entire PPDB resource is freely available under the Creative Commons Attribution 3.0 United States License.
	\item PPDB contains over 150 million paraphrase rules covering three paraphrase types lexical (single word), phrasal (multiword), and syntactic restructuring rules
\end{itemize}




\end{frame}


\begin{frame}
\frametitle{Chatbot}
\begin{columns}[T]
	\begin{column}{.5\textwidth}
		\includegraphics[width=65mm]{seq2seq.png}
		\begin{itemize}
		{\scriptsize 	\item $<PAD>$: During training, inputs in these batches all need to be the same width for the network to do its calculation. 
			\item $<EOS>$: It allows us to tell the decoder where a sentence ends, and it allows the decoder to indicate the same thing in its outputs as well.
		}
		\end{itemize}
	\end{column}
	\begin{column}{.5\textwidth}
		
		\begin{itemize}
{\scriptsize 
			\item $<UNK>$: If you’re training your model on real data, you’ll find you can vastly improve the resource efficiency of your model by ignoring words that don’t show up often enough in your vocabulary to warrant consideration. We replace those with $<UNK>$.
	
		\item $<GO>$: This is the input to the first time step of the decoder to let the decoder know when to start generating output.}
		\end{itemize}
		
	\end{column}
\end{columns}

\end{frame}


\begin{frame}
\frametitle{APD Symptoms}
\begin{table}[]
	\begin{tabular}{|l|llll}
		\cline{1-1}
		\textbf{Listening} &  &  &  &  \\ \cline{1-1}
	Has difficulty locating a sound source.	&  &  &  &  \\ \cline{1-1}
	Has difficulty hearing in noisy background. 	&  &  &  &  \\ \cline{1-1}
	Often asks for repetition or clarification 	&  &  &  &  \\ \cline{1-1}
	\textbf{Speaking}	&  &  &  &  \\ \cline{1-1}
Has difficulty answering open--ended questions	&  &  &  &  \\ \cline{1-1}
May speak in oversimplified short sentences with difficulties in syntax  	&  &  &  &  \\ \cline{1-1}
Mispronounced words, especially long words. 	&  &  &  &  \\ \cline{1-1}
\textbf{Phonological Awareness}	&  &  &  &  \\ \cline{1-1}
Has difficulty focusing during conversations	&  &  &  &  \\ \cline{1-1}
Forgets information that is easily heard 	&  &  &  &  \\ \cline{1-1}
	\end{tabular}
	\caption{A part of checklist for assessing whether the child with APD\footnote{https://kidshear.com.au}}
	\label{1}
\end{table}

\end{frame}

\begin{frame}
\frametitle{Process of creating model}
\begin{figure}
		\includegraphics[width=.8\linewidth]{Spacy.png}
\end{figure}

\begin{itemize}
	\item  MedicBot's models are \textbf{statistical} and every "decision" she makes is a \textbf{prediction}
	\item This precision is based on the examples the model has seen during training
	\item We give the model feedback on its prediction in the form of an \textbf{error gradient} of the\textbf{ loss function} that calculates the difference between the training example and the expected output
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Techniques}
\textbf{Scoring model} 
\begin{columns}[T]
		\begin{column}{.5\textwidth}
			\begin{itemize}
				\item Create the features for the scoring model
				\item Compute the score for these ones
				\item Using the K-Mean Clustering algorithm to cluter the kid
				\item Apply the Elbow and K-validation algorithm to optimize the K-value of K-Mean Clustering algorithm
				\item Make the score table of considered kids
			\end{itemize}
		\end{column}
		\begin{column}{.7\textwidth}
			
			\includegraphics[width=65mm]{f6.jpg}
			
		\end{column}
	\end{columns}
	
\end{frame}

\begin{frame}
\frametitle{Techniques}
\textbf{Preprocessing} 
\begin{columns}[T]
	\begin{column}{.5\textwidth}
		\begin{itemize}
			\item Recognize the subject, verb, object in a given sentence
			\item Recoginze noun, adj, adv, preposition of a sentence
			\item Recognize the entities in a sentence
			\item Recognize the coreference of a sentence
		\end{itemize}
	\end{column}
	\begin{column}{.6\textwidth}
		
		\includegraphics[width=65mm]{f5.jpg}
		
		
	\end{column}
\end{columns}



\begin{flushleft}
	$\rightarrow$ \textit{create the table of features }
\end{flushleft}

\end{frame}
\begin{frame}

\begin{table}[]
	\begin{tabular}{lllll}
		\cline{1-2}
		\multicolumn{1}{|l|}{time of response } & \multicolumn{1}{l|}{$\sum_{t=0}^{T}(t_i)$, $t_i$ the duration of one sentence} &  &   &  \\ \cline{1-2}
		\multicolumn{1}{|l|}{tf-idf(k,d,D)} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}$tf(k,d)\times idf(k,D)$, $k$: term $k$\\ $d$: document $d$; and $d \in D$ \end{tabular} } &  &  &  \\ \cline{1-2}
		\multicolumn{1}{|l|}{coreference} & \multicolumn{1}{l|}{coreference resolution evaluation} &  &  &  \\ \cline{1-2}
		\multicolumn{1}{|l|}{ner} & \multicolumn{1}{l|}{name entity recognization}                                              &  &  &  \\ \cline{1-2}
			\multicolumn{1}{|l|}{similar sentence} & \multicolumn{1}{l|}{similarity evaluation}                                              &  &  &  \\ \cline{1-2}
				\multicolumn{1}{|l|}{mishearing word} & \multicolumn{1}{l|}{spelling and  grammar checking evaluation}                                              &  &  &  \\ \cline{1-2}
					\multicolumn{1}{|l|}{elbow algorithm} & \multicolumn{1}{l|}{choose a small value of k that still has a low SSE}                                              &  &  &  \\ \cline{1-2}
			\multicolumn{1}{|l|}{ROC analysis} & \multicolumn{1}{l|}{		 Receiver Operating Characteristic analysis}                                              &  &  &  \\ \cline{1-2}

	\end{tabular}
\end{table}


\end{frame}
\begin{frame}
\frametitle{Implementation}

\begin{table}[]
	\begin{tabular}{|l|l|}
		\hline
		\textbf{}                                           Requirements              & Content                                   \\ \hline
		\textbf{Python}                                                         & \begin{tabular}[c]{@{}l@{}} 2.6, 2.7, or 3.3+ \end{tabular} \\ \hline
		\textbf{PocketSphinx}                                              & \begin{tabular}[c]{@{}l@{}} large vocabulary speaker independent \\recognition system\end{tabular} \\ \hline
		\begin{tabular}[c]{@{}l@{}}\textbf{PyAudio}\end{tabular} & \begin{tabular}[c]{@{}l@{}} 0.2.11+ (required only if you need to\\ use microphone input, Microphone)\end{tabular} \\ \hline
		
		\textbf{SpeechRecognition}                                                         & \begin{tabular}[c]{@{}l@{}} a process in which a computer or device record\\ the speech of humans and convert it into text  \end{tabular} \\ \hline
		\textbf{Google API Client}                                                         & \begin{tabular}[c]{@{}l@{}} use the Google Cloud Speech API \end{tabular} \\ \hline
		\textbf{FLAC encoder}                                                         & \begin{tabular}[c]{@{}l@{}}if the system is not x86-based \\Windows/Linux/OS X \end{tabular} \\ \hline
	\end{tabular}
	\caption{Requirements of environment}
	\label{tab:setup}
\end{table}
\end{frame}
\begin{frame}
\frametitle{Implementation}
\begin{table}[]
	\begin{tabular}{|l|l|}
		\hline
		\textbf{}                                           Requirements              & Content                                   \\ \hline
		\textbf{SpaCy}                                                         & \begin{tabular}[c]{@{}l@{}} Industrial-Strength NLP \end{tabular} \\ \hline
		\textbf{NeuralCoref}                                              & \begin{tabular}[c]{@{}l@{}} Coreference Resolution in spaCy with Neural Netwo-\\rks \end{tabular} \\ \hline
		\begin{tabular}[c]{@{}l@{}}\textbf{NLTK}\end{tabular} &  \begin{tabular}[c]{@{}l@{}}Natural Language toolkit\end{tabular} \\ \hline
		
		\begin{tabular}[c]{@{}l@{}}\textbf{Scikit-learn} \\\textbf{Tensorflow} \\\textbf{Pytorch}   \end{tabular}                                                     & \begin{tabular}[c]{@{}l@{}} Machine learning library  \end{tabular} \\ \hline
		\textbf{ELMo}                                                         & \begin{tabular}[c]{@{}l@{}} Embeddings from Language Models \end{tabular} \\ \hline
	
	\end{tabular}
	\caption{Requirements of environment}
	\label{tab:setup}
\end{table}
\end{frame}
%\begin{frame}
%\frametitle{Coreference resolution evaluation}
%\begin{figure}
%	\includegraphics[width=.9\linewidth]{Coreference.png}
%\end{figure}
%\begin{itemize}
%	\item \textbf{Singleton classifier}: This classifier 
%	considers  five  representations  which  are  word,  dependency,  
%	string,  numeric,  and  mention
%	\item \textbf{Coreference classifier}: This   
%	classifier     considers     six     representations,     which     are     
%	dependency,  antecedent,  mention,  pair  string,  pair  numeric,  
%	and  mention  pair.
%	\item \textbf{Coreference pair linking} - Mention Ranking Model: The coreference classifier has predicted coreferent scores 
%	for  all  mention  pairs  of  a  targeted  mention
%\end{itemize}
%\end{frame}



\begin{frame}

\frametitle{Unit tests of the system}

\begin{figure}
	
		\includegraphics[width=.7\linewidth]{01.png}
		\includegraphics[width=.9\linewidth]{02.png}
		\includegraphics[width=.7\linewidth]{03.png}
	

\end{figure}

\end{frame}
%------------------------------------------------
\begin{frame}
\frametitle{Methodology}
\begin{itemize}
	\item \textcolor{gray}{Analysis  the  given  APD  symptoms  by  speech  
		recognition  based  on  Deep  learning}
	\item Analysis  the  given  APD  therapy  and  recommend  the
	
	treatment  to  the  APD  children.  Apply  a  natural  language
	
	processing  (NLP)  to  generate  sentences  and  exploit  Deep
	
	learning  to  understand  the  context  of  the  speech
	
	\item \textcolor{gray} {Monitoring  the  process  of  APD  treatment  by  using  speech 	 analysis  based  on  Deep learning}
	
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{Techniques}
\textbf{Proposal for the objective 2 solution}
\begin{columns}	
\begin{column}{.5\textwidth}
	\includegraphics[width=65mm]{f3(1).jpg}
\end{column}
\begin{column}{.5\textwidth}
	
	\begin{itemize}
		\item Propose a training therapy to the APD kid based on the diagnosing report and Task recommendation model
		\item Monnitor the progress of therapy
		\item Update the monitoring data
		\item Suggest the fit training therapy by using reinforcement learning based on recommendation system
	\end{itemize}
	
\end{column}
\end{columns}
\end{frame}


\begin{frame}
\textbf{Task recommendation model \footnote{https://www.thebsa.org.uk}}
\begin{center}
	\includegraphics[width=100mm]{11.png}
\end{center}
\end{frame}

\begin{frame}
\textbf{Tasks and criteria}\\
\begin{columns}	
	\begin{column}{.5\textwidth}
		\includegraphics[width=65mm]{RL.jpg}
	\end{column}
	\begin{column}{.5\textwidth}
	\begin{itemize}
		\item State space $\mathcal{S}$: A state $s_t = \{s_t^i\}, i = (1,N)$
		\item  Action space $\mathcal{A}$: An action $a_t = \{a_t^j\}, j =( 1, K)$
		\item Reward $\mathcal{R}$: $r(s_t,a_t)$ according to the user's feedback
		\item Transition probability $\mathcal{P}$: $p(s_{t+1}|s_t,a_t)$ defines the probebility of state transition from $s_t$ to $s_{t+1}$ when Recommender Agent takes action $a_t$
	\end{itemize}
\end{column}
\end{columns}
\end{frame}



%------------------------------------------------
\begin{frame}
\frametitle{Methodology}
\begin{itemize}
\item \textcolor{gray}{Analysis  the  given  APD  symptoms  by  speech  
recognition  based  on  Deep  learning}
\item \textcolor{gray} {Analysis  the  given  APD  therapy  and  recommend  the 	treatment  to  the  APD  children.  Apply  a  natural  language 	processing  (NLP)  to  generate  sentences  and  exploit  Deep 	learning  to  understand  the  context  of  the  speech}

\item Monitoring  the  process  of  APD  treatment  by  using  speech analysis  based  on  Deep learning

\end{itemize}

\end{frame}
%------------------------------------------------


\begin{frame}
\frametitle{Techniques}
\textbf{Proposal for the objective 3 solution}\\


\begin{itemize}
\item Convert the APD speech to text
\item Analysis the meaning of the text
\item Make the score of the benchmark table

\item Make the client-server model to monitor and evaluate the progress of each patient
\end{itemize}


\end{frame}

\begin{frame}
\begin{figure}
\includegraphics[width=65mm]{f4.jpg}
\end{figure}

Describe the score of the training for the respective user at home
\begin{table}[]
	\begin{tabular}{|l|l|l|l|l|}
		\hline
		\textbf{}                                                         & Observation & Assessment & \begin{tabular}[c]{@{}l@{}}Therapy \\ lesson\end{tabular} & Other \\ \hline
		Listening                                                         &             &            &                                                              &       \\ \hline
		Speaking                                                          &             &            &                                                              &       \\ \hline
		\begin{tabular}[c]{@{}l@{}}Phonological \\ Awareness\end{tabular} &             &            &                                                              &       \\ \hline
	\end{tabular}
	\caption{Benchmark table}
	\label{2}
\end{table}
\end{frame}

\begin{frame}
\frametitle{Client and Master MedicBot}
\begin{columns}	
	\begin{column}{.5\textwidth}
		\includegraphics[width=55mm]{client.jpg}
	\end{column}
	\begin{column}{.5\textwidth}
		
			\includegraphics[width=55mm]{Master.jpg}
		
	\end{column}
\end{columns}
MedicBot Client collects data from User and then send them to the MedicBot Master to store and analysis more (if the problem needs specialists)
\end{frame}
\end{comment}
\section{Work plan}

\begin{frame}
\frametitle{Work plan}
\begin{figure}
	\includegraphics[width=100mm]{plan0.png}
	\caption{Work schedule}
\end{figure}

\begin{columns}[T]
	\begin{column}{.7\textwidth}
	\textbf{Journals:}
	\par [1] Journal of Artificial Intelligence Research 
	\par [2] Technology, Knowledge and Learning
	\par [3] Education and Information Technologies
		
	\end{column}
	\begin{column}{.3\textwidth}
	\textbf{Finished courses:}
	\par (1) DGA1005
	\par (2) MTI830

	\end{column}
\end{columns}



\end{frame}




\begin{frame}{}
\centering \Huge
\emph{Thank You}
\end{frame}
\section{Appendices}
\begin{frame}

\frametitle{List of Intelligent Tutor System}


{\tiny \textbf{ASAT}: AutoTutor Script Authoring Tool is the primary authoring tool for AutoTutor.
Can direct multiple agents and external events/controls.\\
\textbf{ASATA}: AutoTutor Script Authoring Tool for Assessment is a specialized authoring
tool developed with the Educational Testing Service for developing for building dialog-based high stakes assessments.\\
\textbf{AutoMentor (STEM Thinking)}: Uses epistemic analysis of discourse in student group
chats to help students learn how to think and act like STEM (science, technology, engineering, and mathematics) professionals in a multi-party serious game
simulation of urban planning.\\
\textbf{AutoTutor (Computer Literacy)}: Core AutoTutor natural language tutoring system,
which uses expectation-misconception dialog and deep questions, latent
semantic analysis \& regular expressions, and talks with user through the
animated agent(s).\\
\textbf{AutoTutor-3D (Physics):} An extension of AutoTutor for physics, AutoTutor-3D
added interactive three dimensional simulations of physics problems designed
in 3D Studio Max.\\
\textbf{AutoTutor Affect-Sensitive (Computer Literacy)}: AutoTutor-AS detected affect
using natural language and discourse, facial expressions, body posture, and
speech. Feedback considered student emotions and cognitive states. Sometimes
called AutoTutor-ES (Emotion Sensitive).\\
\textbf{AutoTutor Lite (General):} AutoTutor Lite (ATL) is a web-based variant of AutoTutor
designed for simpler authoring, rapid deployment, and integration into thirdparty systems.\\
\textbf{BRCA-Gist (Breast Cancer Risk):} An AutoTutor Lite tutor led by the Miami University, intended to tutor understanding of risk probabilities and personal breast
cancer risk.\\
\textbf{Coh-Metrix}: A linguistic analysis toolkit with over 200 metrics. The “Coh” stands for
cohesion and coherence.\\
\textbf{CSAL Adult Literacy Tutor (Reading):} This tutoring system project for the Center
for the Study of Adult Literacy (CSAL) is intended to help learners who
460 Int J Artif Intell Educ (2014) 24:427–469
struggle with print media, through closer integration of trialogs, web pages, and
multimedia.\\
\textbf{DeepTutor (Physics):} Tutor that uses learning progressions to foster deep learning of physics concepts, as well as enhanced semantic analysis, such as entailment.\\
 }
\end{frame}


\begin{frame}
\frametitle{Appendices}
{\tiny 
	\textbf{GazeTutor (Biology):} Enhanced version of Guru Tutor that monitors and reacts to student gaze.\\
	\textbf{Gnu Tutor (General):} An open source Java release of an early version AutoTutor Lite.\\
\textbf{Guru Tutor (Biology):} Tutoring system for biology designed based on observation of
expert tutors. Uses collaborative lecturing and concept maps to support
learning.\\
\textbf{HURAA (Research Ethics):} The Human Use Regulatory Affairs Advisor for training
ethics in human experiments. AutoTutor agents helped navigate hypertext
multimedia containing case-based reasoning and multiple information retrieval
mechanisms.\\
\textbf{iDRIVE (Computer Literacy, Physics, Biology): }Instruction with Deep-Level Reasoning Questions in Vicarious Environments where the learner observes two
pedagogical agents demonstrate deep explanations and model effective learning behavior (e.g. question-asking).\\
\textbf{iSTART (Reading): }Interactive Strategy Training for Active Reading and Thinking is a
tutoring system for improving reading comprehension by training reading
strategies. Uses multi-agent conversations and specialized semantic analysis
to tutor reading strategies.\\
\textbf{iSTART-ME (Reading):} The Motivationally-Enhanced (ME) version of iSTART
provides tutoring using an interactive game environment.\\
\textbf{MetaTutor (Biology):} Tutors self-regulated learning (SRL) skills inside a hypermedia
setting.\\
\textbf{Operation ARA (Scientific Reasoning)}: Operation Acquiring Research Acumen is an
extension of the Operation ARIES project that adds additional features and
game content.\\
\textbf{Operation ARIES (Scientific Reasoning):} Operation Acquiring Research, Investigative, and Evaluative Skills is a trialog-based tutoring system and serious game
for teaching critical thinking. Learners resolve inconsistent information about
scientific methods inside a serious game narrative.\\}
\end{frame}


\begin{frame}
\frametitle{Appendices}
{\tiny
	\textbf{QUAID: }Question Understanding Aid was a tool to evaluate the comprehensibility of
	questions.\\
	\textbf{SEEK Web Tutor (Critical Thinking):} The Source, Evidence, Explanation, and
Knowledge Tutor was designed to help learners evaluate the credibility and
relevance of information using tutoring-enhanced web search, with spoken
hints, pop-up ratings and metacognitive journaling.\\
\textbf{SKO Modules (General):} Sharable Knowledge Object Modules are encapsulated,
cloud-hosted modules that compose web services to provide tutoring. Currently
being applied to Algebra.\\
\textbf{VCAEST (Medical):} Virtual Civilian Aeromedical Evacuation Sustainment Training
is designed to train civilian medical personnel on federal guidelines for emergency situations and triage.\\
\textbf{WHY2/AutoTutor (Physics):} Extension of AutoTutor that approached tutoring conceptual physics. This was part of a larger WHY2 project that included
Int J Artif Intell Educ (2014) 24:427–469 461\\
\textbf{WHY2/Atlas.} WHY2 was a reference to an old tutoring system called WHY
and the year 2000 (e.g., Y2K).\\
\textbf{Writing-Pal (Writing):} This tutor attempts to improve essay and academic writing\\
skills and provides automated evaluation and feedback on essays. It is related to
the iSTART system.}
\end{frame}

\begin{frame}
\frametitle{Appendices}
Example of association rule: \\
	\includegraphics[width=100mm]{as.png}
\end{frame}
\begin{frame}
\frametitle{Appendices}
\includegraphics[width=80mm]{km.png}

{\tiny Source:  A. {Dahbi}, M. {Mouhir}, Y. {Balouki} and T. {Gadi},"Classification of association rules based on K-means algorithm", in 2016 4th IEEE International Colloquium on Information Science and Technology (CiSt)}
\end{frame}
\begin{frame}
\frametitle{Appendices}

\includegraphics[width=80mm]{api.png}
\end{frame}
\begin{frame}

* we extract contradiction features on which we apply logistic regression to classify the pair as contradictory or not
{\tiny \begin{table}[]
		\begin{tabular}{|l|l|lll}
			\cline{1-2}
			\textbf{Features}             & \textbf{Summary}              &  &  &  \\ \cline{1-2}
			\code{polarity}  &  	\begin{tabular}[c]{@{}l@{}}The polarity features capture the presence (or absence)\\ of linguistic markers of negative polarity contexts \end{tabular}   &  &  &  \\ \cline{1-2}
			\code{numeric} & \begin{tabular}[c]{@{}l@{}}The numeric features recognize
			(mis-)matches \\between numbers, dates, and times\end{tabular} &  &  &  \\ \cline{1-2}
		
			\code{antonymy}          &  \begin{tabular}[c]{@{}l@{}}list of antonyms
			and contrasting words comes from WordNet,\\ from
			which we extract words with direct antonymy links\\
			and expand the list by adding words from the same
			synset\\ as the antonyms \end{tabular}   &  &  &  \\ \cline{1-2}
			
			\code{structural}          & \begin{tabular}[c]{@{}l@{}}determine whether the syntactic structures of the text\\ and
			hypothesis create contradictory statements.   \end{tabular} & &  &  \\ \cline{1-2}
			\code{factivity}          &  \begin{tabular}[c]{@{}l@{}} The context in which a verb\\
			phrase is embedded may give rise to contradiction \end{tabular}  & &  &  \\ \cline{1-2}
			\code{modality}          &\begin{tabular}[c]{@{}l@{}} Simple patterns of modal reasoning are captured\\ by mapping the text and hypothesis to one of \\six modalities ((not )possible,
			(not )actual, (not )necessary),\\ according to the
			presence of predefined modality markers such as\\
			can or maybe \end{tabular} & &  &  \\ \cline{1-2}
		
		
		\end{tabular}
		\caption{Features of contradict detection}
		\label{tab:3}
\end{table}}

\end{frame}
\begin{frame}
\frametitle{Appendices}
\includegraphics[width=110mm]{sent23.png}	\\
\begin{center}
	Table of sentiment score
\end{center}
 \begin{thebibliography}{01}
	{\tiny \bibitem{Calefato} [14] Calefato, F., Lanubile, F., Maiorano, F., Novielli N. (2018) "Sentiment Polarity Detection for Software Development," Empirical Software Engineering, 23(3), pp:1352-1382}
\end{thebibliography}
\end{frame}


\begin{frame}
\frametitle{Appendices}
\includegraphics[width=110mm]{emo.png}	\\
\begin{center}
	Table of Emoticon
\end{center}
{\tiny Source: https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=\&arnumber=7015983\&tag=1}
\end{frame}
\frametitle{SVM dataset}

\begin{frame}

{\tiny \begin{table}[]
		\begin{tabular}{|l|l|lll}
			\cline{1-2}
			\textbf{Features}             & \textbf{Summary}              &  &  &  \\ \cline{1-2}
			\code{number\_of\_contradict\_term}  &  	\begin{tabular}[c]{@{}l@{}} The number of contracdict terms  \end{tabular}   &  &  &  \\ \cline{1-2}
			\code{positive\_polarity} & \begin{tabular}[c]{@{}l@{}} The positive polarity of emoticon\end{tabular} &  &  &  \\ \cline{1-2}
			
			\code{negative\_polarity} & \begin{tabular}[c]{@{}l@{}} The negative polarity of emoticon\end{tabular} &  &  &  \\ \cline{1-2}
			\code{neutral\_polarity} & \begin{tabular}[c]{@{}l@{}} The neutral polarity of emoticon\end{tabular} &  &  &  \\ \cline{1-2}
				\code{Uppercase\_words} & \begin{tabular}[c]{@{}l@{}} Total occurrences of uppercase words  \end{tabular} &  &  &  \\ \cline{1-2}
				\code{Elongated\_words} & \begin{tabular}[c]{@{}l@{}} Total count of tokens with repeated characters \end{tabular} &  &  &  \\ \cline{1-2}
				\code{User\_mentions} & \begin{tabular}[c]{@{}l@{}} Total occurrences of user mentions \end{tabular} &  &  &  \\ \cline{1-2}
				\code{M\_repetitions} & \begin{tabular}[c]{@{}l@{}} The total occurrences of strings with repeated question or exclamation marks \end{tabular} &  &  &  \\ \cline{1-2}
				\code{Laughter} & \begin{tabular}[c]{@{}l@{}} Total occurrences of slang expressions for laughter, such as ‘hahaha’ \\or abbreviations as ‘LOL’ occurring in the
					SentiStrength list of abbreviations \end{tabular} &  &  &  \\ \cline{1-2}
				\code{Sim\_pos } & \begin{tabular}[c]{@{}l@{}}The cosine similarity between the post vector and the objective prototype vector p\_pos  \end{tabular} &  &  &  \\ \cline{1-2}
				\code{Sim\_neg} & \begin{tabular}[c]{@{}l@{}} The cosine similarity between the post vector and the objective prototype vector p\_neg \end{tabular} &  &  &  \\ \cline{1-2}
					\code{Sim\_neu} & \begin{tabular}[c]{@{}l@{}} The cosine similarity between the post vector and the objective prototype vector p\_neu. \end{tabular} &  &  &  \\ \cline{1-2}
			
			
		\end{tabular}
		\caption{Features of sentiment analysis}
		\label{tab:3}
\end{table}}

{\tiny Source: SentiWordNet (http://www.nltk.org)} \\
{\tiny The full lab package including Senti4SD, the DSM and the gold standard is available for download at: https://github.com/collab-uniba/Senti4SD} \\
{\tiny To train and evaluate our classifier for emotion polarity we built a gold standard composed of 4,423 posts from Stack
Overflow. The dataset is well-balanced: 35\% of posts convey positive emotions while 27\% present negative emotions. No emotions are observed for the remaining 38\% of posts, thus they receive the neutral polarity label. \\}
{\tiny Distributional Semantic Model (DSM) \url{https://arxiv.org/ftp/arxiv/papers/1709/1709.02984.pdf}}
\end{frame}
\begin{frame}
\textbf{Advantages of Logistic Regression}: \\
- Lots of ways to regularize your model, and you don’t have to worry as much about your features being correlated, like you do in Naive Bayes. \\
- You also have a nice probabilistic interpretation, unlike decision trees or SVMs, and you can easily update your model to take in new data (using an online gradient descent method), again unlike decision trees or SVMs. \\
- Use it if you want a probabilistic framework (e.g., to easily adjust classification thresholds, to say when you’re unsure, or to get confidence intervals) or if you expect to receive more training data in the future that you want to be able to quickly incorporate into your model.
\end{frame}
\begin{frame}
\includegraphics[width=110mm]{compare.png} \\
\begin{center}
	Table of supervisor learning algorithm comparison
\end{center}


{\tiny Source: https://www.dataschool.io/comparing-supervised-learning-algorithms/}
\end{frame}

\begin{frame}
\frametitle{Appendices}
Linear Regression is a good supervised learning algorithm which is used to predictions problems, it find the target variable by finding a best suitable fit line between the independent and dependent variables.its main advantage is , the best fit line is the line with minimum error from all the points ,it has high efficiency but sometimes this high efficiency created disadvantage which is prone to overfitting of the data (i.e some noisy data also considered as useful data), and also it cant be used when the relation between dependent and independent variable is not linear. \\

{\tiny Source: https://www.analyticsvidhya.com}
\end{frame}
\begin{frame}
\frametitle{Appendices}
\begin{center}
	\includegraphics[width=80mm]{mmm.png} 
\end{center}
{\tiny Source:  Calefato, F., Lanubile, F., Maiorano, F., Novielli N. (2018) "Sentiment Polarity Detection for Software Development," Empirical Software Engineering, 23(3), pp:1352-1382}
\end{frame}
\begin{frame}
\frametitle{Appendices}
Using wikiSynonyms API to get the synonyms keywords \\
\textbf{E.g., Linear regression model }{'Linear modeling', 'Regression coefficient', 'Linear Regression', 'Regression coefficients','Regression line',  'Linear weights', 'Multiple linear regression', 'Line regression', 'Linear regression model', 'Linear trend', 'Multi-linear regression', 'Linear fit', 'Line of regression', 'Linear regression'}

\end{frame}
\begin{frame}
\frametitle{Elbow method example}




\begin{columns}
	\begin{column}{.55\textwidth}
	\begin{center}
		\includegraphics[width=50mm]{elbow2.png} 
	\end{center}
		
	\end{column}
	\begin{column}{.55\textwidth}
		
-	Compute clustering algorithm (e.g., k-means clustering) for different values of k. For instance, by varying k from 1 to 10 clusters. \\
-	For each k, calculate the total within-cluster sum of square (wss).\\
-	Plot the curve of wss according to the number of clusters k.\\
-	The location of a bend (knee) in the plot is generally considered as an indicator of the appropriate number of clusters.\\


\end{column}

\end{columns}
{\tiny Source: https://towardsdatascience.com}

\end{frame}

\begin{frame}
\frametitle{Cohen Kappa }

\begin{columns}
	\begin{column}{.55\textwidth}
		\begin{figure}
		\includegraphics[width=55mm]{kappa_table.png}
	\end{figure}
	
	\end{column}
\begin{column}{.55\textwidth}
	
	
	* The Kappa statistic (or value) is a metric that compares an \textbf{Observed Accuracy} with an\textbf{ Expected Accuracy }(random chance). \\ * Computation of Observed Accuracy and Expected Accuracy is integral to comprehension of the kappa statistic, and is most easily illustrated through use of a confusion matrix
	
	
\end{column}

\end{columns}


 \begin{thebibliography}{01}
	{\tiny \bibitem{Calefato} [16]Muhamad Isa S, Eka Suryana M, Ali Akbar M, Noviyanto A, Jatmiko W, Murni Arymurthy A. Performance Analysis of ECG Signal Compression using SPIHT. International Journal on Smart Sensing \& Intelligent Systems. 2013}
\end{thebibliography}


\end{frame}
\begin{frame}
The graph at right shows three ROC curves representing excellent, good, and worthless tests plotted on the same graph. The accuracy of the test depends on how well the test separates the group being tested into those with and without the disease in question. Accuracy is measured by the area under the ROC curve. An area of 1 represents a perfect test; an area of .5 represents a worthless test. A rough guide for classifying the accuracy of a diagnostic test is the traditional academic point system:\\

.90-1 = excellent (A)\\
.80-.90 = good (B)\\
.70-.80 = fair (C)\\
.60-.70 = poor (D)\\
.50-.60 = fail (F) \\


{\tiny Source: http://gim.unmc.edu/dxtests/roc3.htm} \\
{\tiny https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4893763/}
\end{frame}
\begin{frame}
\frametitle{SentiwordNet}


- SentiWordNet is a lexical resource for opinion mining. SentiWordNet
assigns to each synset of WordNet three sentiment scores: positivity,
negativity, objectivity. \\

- SentiWordNet v3.0 is based on WordNet version 3.0.
 WordNet website: http://wordnet.princeton.edu/ \\

- The pair (POS,ID) uniquely identifies a WordNet (3.0) synset.\\
 The values PosScore and NegScore are the positivity and negativity
 score assigned by SentiWordNet to the synset. \\
- The objectivity score can be calculated as:
 ObjScore = 1 - (PosScore + NegScore) \\
- SynsetTerms column reports the terms, with sense number, belonging
 to the synset (separated by spaces).

\end{frame}


\begin{frame}
\frametitle{Objective 3 | Methodology | Examples}
We have the topic: \\
{\tiny \textbf{What are advantages of Artificial Neural Networks over Support Vector Machines?} \\}
{\tiny User 1: \code{"ANN (Artificial Neural Networks) and SVM (Support Vector Machines) are two popular strategies for supervised machine learning and classification. It's not often clear which method is better for a particular project, and I'm certain the answer is always "it depends." Often, a combination of both along with Bayesian classification is used."} $\rightarrow$ \textbf{Proximity the topic }\\	
	User 2: \code{"Sweet :) Happy hacking!"} $\rightarrow$ \textbf{No conflict}\\	
	User 1: \code{"What do you think about the weather today?"}  $\rightarrow$\textbf{ No Proximity}\\		
		User 1: \code{" So Bad >"< It is very terible!"} $\rightarrow$ \textbf{conflict}\\
}

\end{frame}
\begin{frame}
\frametitle{Objective 3 | Methodology }
{\scriptsize \textbf{Perplexity}:\\
-Perplexity is a measurement of how well a probability model predicts a test data. In the context of Natural Language Processing, perplexity is one way to evaluate language models.\\
-Perplexity is just an exponentiation of the entropy!\\
-Low perplexity is good and high perplexity is bad since the perplexity is the exponentiation of the entropy \\
\textbf{F1-score:}\\
F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution. The F1 score lies between the value of the recall and the value of the precision, and tends to lie closer to the smaller of the two, so high values for the F1 score are only possible if both the precision and recall are large. \code{F1 = 2 * (precision * recall) / (precision + recall)}} \\
{\tiny Source: wikipedia}
	\end{frame}
\begin{comment}
\begin{frame}
\frametitle{Training spaCy’s Statistical Models}
{\footnotesize \par + spaCy is the best way to prepare text for deep learning. 
 \par + with spaCy, you can easily construct linguistically sophisticated statistical models for a variety of NLP problems
 \par + spaCy's models are statistical and every "decision" they make is a prediction. This prediction is based on the examples the model has seen during training. 
 	\includegraphics[width=100mm]{Spacy.png}}
 {\tiny Reference:}
 {\tiny \href{https://explosion.ai/demos/displacy}{https://explosion.ai/demos/displacy}
 }
\end{frame}

\begin{frame}
\par (1) Syntax tree demo:  \href{https://explosion.ai/demos/displacy}{Syntax tree display}
\par (2) Seq2Seq demo: 
\href{http://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/}{Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)}
\par (3) 
BFS demo: 
\href{https://www.cs.usfca.edu/~galles/visualization/BFS.html}{
	Breadth-First Search
}

\end{frame}
%------------------------------------------------
\end{comment}


\end{document}